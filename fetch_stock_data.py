import yfinance as yf                       # Yahoo Financeì—ì„œ ì£¼ì‹ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
import pandas as pd                         # ë°ì´í„°í”„ë ˆì„ì„ ë‹¤ë£¨ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import psycopg2                             # PostgreSQLê³¼ ì—°ê²°í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
import argparse                             # ì»¤ë§¨ë“œë¼ì¸ì—ì„œ ì¸ìë¥¼ ë°›ì„ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
import os                                   # íŒŒì¼ ë° ë””ë ‰í„°ë¦¬ ì¡°ì‘ì„ ìœ„í•œ ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
from datetime import datetime, timedelta    # ë‚ ì§œ ë° ì‹œê°„ ê´€ë ¨ ì‘ì—…ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import pandas_market_calendars as mcal      # ì£¼ì‹ ì‹œì¥ì˜ íœ´ì¥ì¼ì„ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬

# PostgreSQL ì—°ê²° ì •ë³´
DB_CONFIG = {
    "dbname": "hwechang",   # ì‚¬ìš©í•  PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„
    "user": "hwechang",     # ë°ì´í„°ë² ì´ìŠ¤ ì ‘ì† ì‚¬ìš©ìëª…
    "password": "hwechang", # ë°ì´í„°ë² ì´ìŠ¤ ë¹„ë°€ë²ˆí˜¸
    "host": "10.0.1.160",   # ë°ì´í„°ë² ì´ìŠ¤ ì„œë²„ì˜ IP ì£¼ì†Œ ë˜ëŠ” í˜¸ìŠ¤íŠ¸ë„¤ì„
    "port": "5432"          # PostgreSQL í¬íŠ¸
}


# ê¸°ë³¸ ì¢…ëª© ë¦¬ìŠ¤íŠ¸
DEFAULT_TICKERS = [
    "AAPL", "MSFT", "AMZN", "GOOGL", "TSLA", "CB", "JPM", "JNJ", "V", "WMT",
    "PG", "NVDA", "HD", "UNH", "DIS", "PYPL", "BAC", "VZ", "NFLX", "KO",
    "PEP", "INTC", "CSCO", "MRK", "XOM", "T", "PFE", "ABBV", "CRM", "MCD",
    "WFC", "ACN", "DHR", "TXN", "LLY", "ORCL", "NKE", "LIN", "MDT", "AMD",
    "COST", "HON", "UPS", "TMO", "C", "LMT", "GS", "NOW", "ADP", "SBUX",
    "AMGN", "CAT", "ISRG", "MS", "DE", "CVS", "BMY", "LOW", "ABT", "CI",
    "EQIX", "SCHW", "BKNG", "CME", "CHTR", "PLD", "SQ", "SPGI", "MMC", "EL",
    "BLK", "ADI", "REGN", "CB", "BSX", "ZTS", "ECL", "AXP", "HCA", "KMB",
    "SNPS", "PGR", "APD", "CDNS", "AON", "MCO", "MELI", "KLAC", "IDXX", "ROP",
    "TRV", "CRWD", "GPN", "VRTX", "FDX", "AZO", "BIIB", "ORLY", "WBA", "DXCM",
    "005930.KS", "000660.KS", "035420.KS", "207940.KS", "005380.KS",
    "051910.KS", "035720.KS", "068270.KS", "028260.KS", "006400.KS",
    "000270.KS", "012330.KS", "055550.KS", "105560.KS", "323410.KS",
    "086790.KS", "033780.KS", "009150.KS", "034220.KS", "011170.KS",
    "018260.KS", "032640.KS", "024110.KS", "011200.KS", "000810.KS",
    "138930.KS", "088980.KS", "010140.KS", "005490.KS", "008770.KS",
    "002790.KS", "003490.KS", "002380.KS", "003670.KS", "021240.KS",
    "298020.KS", "000100.KS", "097950.KS", "010620.KS", "271560.KS",
    "000120.KS", "010130.KS", "004020.KS", "023530.KS", "069960.KS",
    "011780.KS", "004370.KS", "005300.KS", "011090.KS", "000880.KS",
    "263800.KQ", "108320.KQ", "041510.KQ", "035900.KQ", "122990.KQ",
    "089970.KQ", "290660.KQ", "232140.KQ", "226330.KQ", "039030.KQ",
    "200470.KQ", "095700.KQ", "078600.KQ", "064290.KQ", "054920.KQ",
    "025900.KQ", "085670.KQ", "290520.KQ", "143240.KQ", "214320.KQ",
    "059100.KQ", "052790.KQ", "121800.KQ", "080220.KQ", "251970.KQ",
    "035760.KQ", "263750.KQ", "293490.KQ", "278280.KQ", "068760.KQ",
    "298540.KQ", "047810.KQ", "100130.KQ", "030200.KQ", "196170.KQ",
    "138040.KQ", "131370.KQ", "025980.KQ", "096530.KQ", "278650.KQ",
    "054180.KQ", "067160.KQ", "032190.KQ", "121600.KQ", "073490.KQ",
    "214260.KQ", "278990.KQ", "046210.KQ", "178320.KQ", "192080.KQ"
]

def create_log_tables_if_not_exists():
    """ PostgreSQLì— í…Œì´ë¸” ë° ì¸ë±ìŠ¤ê°€ ì—†ì„ ê²½ìš° ìƒì„± """
    try:
        conn = psycopg2.connect(**DB_CONFIG)    # DB ì—°ê²°
        cur = conn.cursor()                     # ì»¤ì„œ ìƒì„±
        
        # ë¡œê·¸ í…Œì´ë¸” ìƒì„± ì¿¼ë¦¬
        cur.execute("""
            CREATE TABLE IF NOT EXISTS stock_data_log (
                log_id SERIAL PRIMARY KEY,
                step VARCHAR(50) NOT NULL,
                log_type VARCHAR(50) NOT NULL,
                ticker VARCHAR(20),
                message TEXT,
                from_date DATE,
                to_date DATE,
                start_time TIMESTAMP DEFAULT NOW(),
                end_time TIMESTAMP,
                result VARCHAR(20),
                created_at TIMESTAMP DEFAULT NOW()
            );
        """)

        # ì¸ë±ìŠ¤ ì¶”ê°€ (ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´)
        cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_stock_data_log_step ON stock_data_log(step);
            CREATE INDEX IF NOT EXISTS idx_stock_data_log_log_type ON stock_data_log(log_type);
            CREATE INDEX IF NOT EXISTS idx_stock_data_log_ticker ON stock_data_log(ticker);
        """)
        
        conn.commit()   # ë³€ê²½ ì‚¬í•­ ì €ì¥
        cur.close()     # ì»¤ì„œ ë‹«ê¸°
        conn.close()    # DB ì—°ê²° ì¢…ë£Œ
    except Exception as e:
        print(f"[í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜] {e}")


def log_to_db(step, log_type, ticker, message, from_date, to_date, start_time=None, end_time=None, result=None):
    """ PostgreSQLì— ë¡œê·¸ ì €ì¥ """
    log_msg = f"[{step}] {log_type} | {ticker or 'ì „ì²´'} | {message} | {from_date} ~ {to_date}"
    print(log_msg)
    
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
        cur.execute(
            """
            INSERT INTO stock_data_log (step, log_type, ticker, message, from_date, to_date, start_time, end_time, result, created_at)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())
            """,
            (step, log_type, ticker, message, from_date, to_date, start_time, end_time, result)
        )
        conn.commit()
        cur.close()
        conn.close()
    except Exception as e:
        print(f"[ERROR] ë¡œê·¸ ì…ë ¥ ì‹¤íŒ¨: {e}")  # â† ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥ ì¶”ê°€
        # DB ì €ì¥ ì‹¤íŒ¨ ì‹œ log_backup.txtì— ë°±ì—…
        with open("log_backup.txt", "a") as log_file:
            log_file.write(f"{log_msg} | [ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨] {e}\n")


def is_market_closed(date):
    """ì£¼ì–´ì§„ ë‚ ì§œê°€ ë¯¸êµ­ ì¦ì‹œ íœ´ì¥ì¼ì¸ì§€ í™•ì¸ (ê³µì‹ íœ´ì¥ì¼ + ì£¼ë§)"""
    nyse = mcal.get_calendar("NYSE")        # ë‰´ìš• ì¦ê¶Œê±°ë˜ì†Œ(NYSE) ìº˜ë¦°ë” ê°€ì ¸ì˜¤ê¸°
    holidays = nyse.holidays().holidays     # íœ´ì¥ì¼ ëª©ë¡

    # ì£¼ë§ ì—¬ë¶€ í™•ì¸ (í† ìš”ì¼: 5, ì¼ìš”ì¼: 6)
    is_weekend = date.weekday() in [5, 6]

    # íœ´ì¥ì¼ ë˜ëŠ” ì£¼ë§ì´ë©´ True ë°˜í™˜
    return date in holidays or is_weekend


def save_csv(data, from_date):
    """ CSV íŒŒì¼ì„ ì €ì¥í•  í´ë”ë¥¼ ìƒì„±í•˜ê³  ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ """
    try:
        # `from_date`ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ `-`ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì—°ë„(year), ì›”(month), ì¼(day) ë¶„ë¦¬
        year, month, _ = str(from_date).split("-")

        # ì €ì¥í•  í´ë” ê²½ë¡œ ìƒì„± (ì˜ˆ: `csv/2025/01/`)
        folder_path = os.path.join("csv", year, month)

        # `os.makedirs()`ë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë” ìƒì„± (`exist_ok=True`ë¡œ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ë¬´ì‹œ)
        os.makedirs(folder_path, exist_ok=True)

        # CSV íŒŒì¼ëª… ìƒì„± (ì˜ˆ: `stock_data_2025-01-14.csv`)
        file_name = f"stock_data_{from_date}.csv"

        # í´ë” ê²½ë¡œì™€ íŒŒì¼ëª…ì„ ê²°í•©í•˜ì—¬ ìµœì¢… ì €ì¥ ê²½ë¡œ ì„¤ì •
        file_path = os.path.join(folder_path, file_name)

        # `Capital Gains` ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì œê±° (ëŒ€ì†Œë¬¸ì ì •í™•íˆ ë§ì¶°ì•¼ í•¨)
        data = data.drop(columns=["Capital Gains"], errors="ignore")

        # ë°ì´í„°í”„ë ˆì„ì„ CSV íŒŒì¼ë¡œ ì €ì¥ (index=Falseë¡œ ì¸ë±ìŠ¤ëŠ” ì €ì¥í•˜ì§€ ì•ŠìŒ)
        data.to_csv(file_path, index=False)

        # CSV íŒŒì¼ ê²½ë¡œë¥¼ ë¡œê·¸ íŒŒì¼(`csv_files.log`)ì— ì €ì¥ (Parquet ë³€í™˜ì„ ìœ„í•´)
        log_file_path = "/home/hwechang_jeong/stock/exe/csv_files.log"
        with open(log_file_path, "a") as log_file:
            log_file.write(file_path + "\n")  # íŒŒì¼ ê²½ë¡œë¥¼ í•œ ì¤„ì”© ì¶”ê°€ ê¸°ë¡

        return file_path  # ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë°˜í™˜
    except Exception as e:
        print(f"[ERROR] CSV ì €ì¥ ì‹¤íŒ¨: {e}")  # ì˜ˆì™¸ ë°œìƒ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥
        return None  # ì‹¤íŒ¨ ì‹œ None ë°˜í™˜


def fetch_stock_data(tickers, from_date, to_date):
    """ ì£¼ì‹ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê³  CSV ë° DBì— ì €ì¥ """
    start_time = datetime.now()  # ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ì‹œê°„ ê¸°ë¡
    log_to_db("ì‹œì‘", "INFO", "ALL", "ë°ì´í„° ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ ì‹œì‘", from_date, to_date, start_time=start_time, end_time=start_time,
              result="ì§„í–‰ ì¤‘")

    current_date = datetime.strptime(from_date, "%Y-%m-%d")

    data_found = False  # ğŸ”¥ ìµœì†Œ 1ê°œë¼ë„ ë°ì´í„°ë¥¼ ì €ì¥í–ˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í”Œë˜ê·¸

    while current_date <= datetime.strptime(to_date, "%Y-%m-%d"):
        check_date = current_date.date()
        extract_start_time = datetime.now()  # ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ì‹œê°„
        print(f"[ë‚ ì§œ í™•ì¸] {check_date} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")

        if is_market_closed(check_date):
            log_to_db("íœ´ì¥", "INFO", "ALL", f"{check_date} íœ´ì¥ì¼(ì£¼ë§í¬í•¨)", check_date, check_date,
                      start_time=extract_start_time, end_time=datetime.now(), result="íœ´ì¥")
        else:
            all_data = []  # ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

            for ticker in tickers:
                try:
                    stock = yf.Ticker(ticker)
                    stock_data = stock.history(start=str(check_date), end=str(check_date + timedelta(days=1)))

                    if stock_data.empty:
                        log_to_db("ì¶”ì¶œ", "ERROR", ticker, f"ë°ì´í„° ì—†ìŒ", check_date, check_date,
                                  start_time=extract_start_time, end_time=datetime.now(), result="ì‹¤íŒ¨")
                        continue

                    stock_data = stock_data.reset_index()
                    stock_data["Ticker"] = ticker
                    all_data.append(stock_data)

                    log_to_db("ì¶”ì¶œ", "INFO", ticker, f"ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ", check_date, check_date,
                              start_time=extract_start_time, end_time=datetime.now(), result="ì„±ê³µ")

                except Exception as e:
                    log_to_db("ì¶”ì¶œ", "ERROR", ticker, f"ì˜¤ë¥˜: {e}", check_date, check_date, start_time=extract_start_time,
                              end_time=datetime.now(), result="ì‹¤íŒ¨")

            if all_data:
                csv_start_time = datetime.now()
                combined_data = pd.concat(all_data, ignore_index=True)
                file_path = save_csv(combined_data, check_date)

                if file_path:
                    log_to_db("CSV ì €ì¥", "INFO", "ALL", f"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {file_path}", check_date, check_date,
                              start_time=csv_start_time, end_time=datetime.now(), result="ì„±ê³µ")
                    data_found = True  # âœ… ìµœì†Œ 1ê°œë¼ë„ ë°ì´í„° ì €ì¥ì´ ë˜ì—ˆìŒ
                else:
                    log_to_db("CSV ì €ì¥", "ERROR", "ALL", "CSV ì €ì¥ ì‹¤íŒ¨", check_date, check_date, start_time=csv_start_time,
                              end_time=datetime.now(), result="ì‹¤íŒ¨")
            else:
                log_to_db("ì¶”ì¶œ", "ERROR", "ALL", "ìˆ˜ì§‘ëœ ë°ì´í„° ì—†ìŒ", check_date, check_date, start_time=extract_start_time,
                          end_time=datetime.now(), result="ì‹¤íŒ¨")

        current_date += timedelta(days=1)

    end_time = datetime.now()

    # âœ… ì „ì²´ ê³¼ì •ì—ì„œ ë‹¨ í•œ ê°œë¼ë„ ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if data_found:
        log_to_db("ì™„ë£Œ", "INFO", "ALL", "ë°ì´í„° ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ", from_date, to_date, start_time=start_time, end_time=end_time,
                  result="ì„±ê³µ")
    else:
        log_to_db("ì™„ë£Œ", "ERROR", "ALL", "ëª¨ë“  ë‚ ì§œì— ëŒ€í•´ ë°ì´í„° ì—†ìŒ", from_date, to_date, start_time=start_time,
                  end_time=end_time, result="ì‹¤íŒ¨")



def main():
    """ ì‹¤í–‰ ì½”ë“œ: ì»¤ë§¨ë“œë¼ì¸ ì¸ì ì²˜ë¦¬ ë° ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰ """
    parser = argparse.ArgumentParser(description="ì£¼ì‹ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ì €ì¥í•˜ëŠ” í”„ë¡œê·¸ë¨")

    parser.add_argument("--tickers", nargs="+", default=DEFAULT_TICKERS, help="ì¡°íšŒí•  ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: AAPL MSFT TSLA)")
    # parser.add_argument("--from_date", type=str, default=(datetime.today() - timedelta(days=1)).strftime("%Y-%m-%d"),
    #                     help="ì‹œì‘ ë‚ ì§œ (ì˜ˆ: 2024-01-01)")
    # parser.add_argument("--to_date", type=str, default=(datetime.today() - timedelta(days=1)).strftime("%Y-%m-%d"),
    #                     help="ì¢…ë£Œ ë‚ ì§œ (ì˜ˆ: 2024-01-05)")

    parser.add_argument("--from_date", type=str, default='2025-01-14',
                        help="ì‹œì‘ ë‚ ì§œ (ì˜ˆ: 2024-01-01)")
    parser.add_argument("--to_date", type=str, default='2025-01-22',
                        help="ì¢…ë£Œ ë‚ ì§œ (ì˜ˆ: 2024-01-05)")
    args = parser.parse_args()

    create_log_tables_if_not_exists()  # ë¡œê·¸ í…Œì´ë¸” ìƒì„±
    fetch_stock_data(args.tickers, args.from_date, args.to_date)


if __name__ == "__main__":
    main()



"""
python3 stock_fetch.py --tickers AAPL MSFT TSLA --from_date 2024-02-01 --to_date 2024-02-07

"""